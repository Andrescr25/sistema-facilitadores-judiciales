#!/usr/bin/env python3
"""
Demo del chat console para el bot de Facilitadores Judiciales.
VersiÃ³n simplificada que funciona sin modelo GPT4All real.
"""

import os
import sys
import logging
from typing import List, Dict, Any
from pathlib import Path

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Importaciones de LangChain
try:
    from langchain.vectorstores import Chroma
    from langchain.embeddings import SentenceTransformerEmbeddings
    from langchain.schema import Document
except ImportError as e:
    logger.error(f"Error importando LangChain: {e}")
    logger.error("Ejecuta: pip install langchain langchain-community")
    sys.exit(1)

# ConfiguraciÃ³n
PERSIST_DIR = os.getenv("VECTOR_DB_DIR", "./data/chroma")
MODEL_EMBED = "all-MiniLM-L6-v2"

class MockLLM:
    """
    Mock del LLM para demostraciÃ³n sin modelo real.
    """
    
    def __init__(self):
        self.name = "Mock LLM (Demo)"
    
    def __call__(self, prompt: str, **kwargs) -> str:
        """
        Simula respuestas del LLM basadas en palabras clave.
        """
        prompt_lower = prompt.lower()
        
        # Respuestas predefinidas basadas en palabras clave
        if "requisitos" in prompt_lower and "facilitador" in prompt_lower:
            return """Para ser facilitador judicial se requiere:
1. TÃ­tulo profesional en derecho, psicologÃ­a, trabajo social o Ã¡reas afines
2. Experiencia mÃ­nima de 3 aÃ±os en resoluciÃ³n de conflictos
3. CertificaciÃ³n vigente del Consejo Superior de la Judicatura
4. No tener antecedentes disciplinarios
5. Renovar certificaciÃ³n cada 3 aÃ±os

Fuente: marco_legal.txt"""
        
        elif "duraciÃ³n" in prompt_lower or "dura" in prompt_lower:
            return """El procedimiento de conciliaciÃ³n judicial tiene una duraciÃ³n mÃ¡xima de 30 dÃ­as hÃ¡biles desde la admisiÃ³n de la solicitud.

El proceso incluye las siguientes fases:
- Fase de admisiÃ³n
- Fase de citaciÃ³n  
- Fase de audiencia
- Fase de homologaciÃ³n

Fuente: ejemplo_procedimiento.txt"""
        
        elif "tÃ©cnicas" in prompt_lower or "facilitaciÃ³n" in prompt_lower:
            return """Las tÃ©cnicas de facilitaciÃ³n recomendadas incluyen:

1. Escucha activa: Prestar atenciÃ³n completa a lo que dicen las partes
2. Parafraseo: Repetir con palabras propias lo expresado
3. Preguntas abiertas: Fomentar la reflexiÃ³n y el diÃ¡logo
4. ReformulaciÃ³n: Ayudar a expresar mejor los intereses
5. Lluvia de ideas: Generar opciones creativas de soluciÃ³n

Fuente: guia_facilitador.txt"""
        
        elif "costos" in prompt_lower or "precio" in prompt_lower:
            return """Los costos del procedimiento de conciliaciÃ³n son:

- Tasa de admisiÃ³n: $50.000
- Honorarios del facilitador: $100.000 por sesiÃ³n
- Gastos de notificaciÃ³n: $25.000 por parte

El acuerdo conciliatorio tiene fuerza ejecutiva y es equivalente a una sentencia judicial.

Fuente: ejemplo_procedimiento.txt"""
        
        elif "fases" in prompt_lower or "etapas" in prompt_lower:
            return """Las fases del procedimiento de conciliaciÃ³n son:

1. Fase de admisiÃ³n: El juez evalÃºa si la solicitud cumple los requisitos
2. Fase de citaciÃ³n: Se notifica a todas las partes involucradas
3. Fase de audiencia: Se realiza la sesiÃ³n de conciliaciÃ³n
4. Fase de homologaciÃ³n: Se aprueba el acuerdo alcanzado

Fuente: ejemplo_procedimiento.txt"""
        
        else:
            return """No tengo informaciÃ³n suficiente en los documentos provistos para responder a esa pregunta especÃ­fica. 

Los documentos disponibles contienen informaciÃ³n sobre:
- Procedimientos de conciliaciÃ³n judicial
- Requisitos para facilitadores judiciales
- TÃ©cnicas de facilitaciÃ³n
- Marco legal aplicable
- Costos y duraciÃ³n de procesos

Por favor, reformula tu pregunta usando tÃ©rminos relacionados con estos temas."""

class FacilitadorBotDemo:
    """
    Bot de demostraciÃ³n para facilitadores judiciales con RAG.
    """
    
    def __init__(self, persist_dir: str):
        self.persist_dir = persist_dir
        self.vectordb = None
        self.llm = MockLLM()
        
    def load_vector_database(self) -> bool:
        """
        Carga la base de datos vectorial existente.
        """
        try:
            logger.info("Cargando base de datos vectorial...")
            
            # Verificar que existe la base de datos
            if not Path(self.persist_dir).exists():
                logger.error(f"Base de datos no encontrada en {self.persist_dir}")
                logger.error("Ejecuta primero: python ingest.py")
                return False
            
            # Cargar embeddings
            embedder = SentenceTransformerEmbeddings(model_name=MODEL_EMBED)
            
            # Cargar base de datos vectorial
            self.vectordb = Chroma(
                persist_directory=self.persist_dir,
                embedding_function=embedder
            )
            
            # Verificar que hay documentos
            doc_count = self.vectordb._collection.count()
            if doc_count == 0:
                logger.error("La base de datos estÃ¡ vacÃ­a")
                return False
            
            logger.info(f"âœ… Base de datos cargada con {doc_count} documentos")
            return True
            
        except Exception as e:
            logger.error(f"Error cargando base de datos: {e}")
            return False
    
    def search_documents(self, query: str, k: int = 3) -> List[Document]:
        """
        Busca documentos relevantes en la base de datos vectorial.
        """
        if not self.vectordb:
            return []
        
        try:
            results = self.vectordb.similarity_search(query, k=k)
            return results
        except Exception as e:
            logger.error(f"Error buscando documentos: {e}")
            return []
    
    def ask(self, question: str) -> Dict[str, Any]:
        """
        Procesa una pregunta y devuelve la respuesta con fuentes.
        """
        if not self.vectordb:
            return {
                "answer": "Error: Base de datos no cargada",
                "sources": []
            }
        
        try:
            logger.info(f"Procesando pregunta: {question}")
            
            # Buscar documentos relevantes
            relevant_docs = self.search_documents(question, k=3)
            
            # Crear contexto para el LLM
            context = ""
            sources = []
            
            for doc in relevant_docs:
                context += f"\n--- {doc.metadata.get('filename', 'Desconocido')} ---\n"
                context += doc.page_content + "\n"
                
                sources.append({
                    "filename": doc.metadata.get("filename", "Desconocido"),
                    "content": doc.page_content[:200] + "...",
                    "source": doc.metadata.get("source", "Desconocido")
                })
            
            # Crear prompt para el LLM
            prompt = f"""Eres un asistente especializado en facilitaciÃ³n judicial. Responde la pregunta basÃ¡ndote en el contexto proporcionado.

CONTEXTO:
{context}

PREGUNTA: {question}

RESPUESTA:"""
            
            # Generar respuesta
            answer = self.llm(prompt)
            
            logger.info(f"Respuesta generada con {len(sources)} fuentes")
            
            return {
                "answer": answer,
                "sources": sources
            }
            
        except Exception as e:
            logger.error(f"Error procesando pregunta: {e}")
            return {
                "answer": f"Error procesando la pregunta: {str(e)}",
                "sources": []
            }
    
    def test_retrieval(self, test_queries: List[str]) -> None:
        """
        Prueba el sistema con consultas de ejemplo.
        """
        logger.info("ğŸ§ª Ejecutando pruebas del sistema...")
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n--- PRUEBA {i} ---")
            print(f"Pregunta: {query}")
            
            result = self.ask(query)
            
            print(f"Respuesta: {result['answer']}")
            
            if result['sources']:
                print("Fuentes consultadas:")
                for j, source in enumerate(result['sources'], 1):
                    print(f"  {j}. {source['filename']}")
            
            print("-" * 50)

def main():
    """
    FunciÃ³n principal del chat console demo.
    """
    print("ğŸ¤– Bot de Facilitadores Judiciales - Chat Console (DEMO)")
    print("=" * 70)
    print("âš ï¸  NOTA: Esta es una versiÃ³n de demostraciÃ³n que simula el LLM")
    print("   Para usar el modelo real, necesitas descargar un modelo GPT4All")
    print("=" * 70)
    
    # Crear instancia del bot
    bot = FacilitadorBotDemo(PERSIST_DIR)
    
    # Cargar base de datos vectorial
    if not bot.load_vector_database():
        print("âŒ Error cargando la base de datos. Revisa los logs.")
        return
    
    # Ejecutar pruebas de ejemplo
    test_queries = [
        "Â¿CuÃ¡les son los requisitos para ser facilitador judicial?",
        "Â¿CuÃ¡nto dura el procedimiento de conciliaciÃ³n?",
        "Â¿QuÃ© tÃ©cnicas de facilitaciÃ³n se recomiendan?",
        "Â¿CuÃ¡les son los costos del procedimiento?",
        "Â¿CuÃ¡les son las fases del procedimiento?"
    ]
    
    print("\nğŸ§ª Ejecutando pruebas automÃ¡ticas...")
    bot.test_retrieval(test_queries)
    
    # Modo interactivo
    print("\nğŸ’¬ Modo interactivo (escribe 'exit' para salir)")
    print("=" * 70)
    
    while True:
        try:
            question = input("\nğŸ¤” Pregunta: ").strip()
            
            if question.lower() in ['exit', 'salir', 'quit']:
                print("ğŸ‘‹ Â¡Hasta luego!")
                break
            
            if not question:
                continue
            
            # Procesar pregunta
            result = bot.ask(question)
            
            # Mostrar respuesta
            print(f"\nğŸ¤– Respuesta: {result['answer']}")
            
            # Mostrar fuentes si las hay
            if result['sources']:
                print("\nğŸ“š Fuentes consultadas:")
                for i, source in enumerate(result['sources'], 1):
                    print(f"  {i}. {source['filename']}")
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Â¡Hasta luego!")
            break
        except Exception as e:
            print(f"âŒ Error: {e}")

if __name__ == "__main__":
    main()
