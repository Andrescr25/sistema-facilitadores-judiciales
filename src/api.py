#!/usr/bin/env python3
"""
API optimizada para el bot de Facilitadores Judiciales.
Sistema r√°pido y eficiente con cache inteligente y respuestas precomputadas.
"""

import os
import sys
import logging
import re
import asyncio
import time
import json
import hashlib
from typing import Dict, Any, List, Optional, AsyncGenerator

# Cargar variables de entorno desde config/config.env
from dotenv import load_dotenv
load_dotenv("config/config.env")
load_dotenv()  # .env si existe (prioridad)
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from collections import defaultdict, OrderedDict
from pathlib import Path

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Importaciones de FastAPI
try:
    from fastapi import FastAPI, HTTPException, Request, BackgroundTasks
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.responses import StreamingResponse, JSONResponse
    from pydantic import BaseModel
    from contextlib import asynccontextmanager
    import uvicorn
except ImportError as e:
    logger.error(f"Error importando FastAPI: {e}")
    sys.exit(1)

# Importaciones de LangChain
try:
    from langchain_community.vectorstores import Chroma
    from langchain_community.embeddings import SentenceTransformerEmbeddings
    from langchain.schema import Document
except ImportError as e:
    logger.error(f"Error importando LangChain: {e}")
    sys.exit(1)

# Intentar importar llama_cpp para usar el modelo local GGUF
try:
    from llama_cpp import Llama  # type: ignore
    _LLAMA_AVAILABLE = True
except Exception:
    _LLAMA_AVAILABLE = False

# Intentar importar Groq para API en la nube
try:
    from groq import Groq  # type: ignore
    _GROQ_AVAILABLE = True
except Exception:
    _GROQ_AVAILABLE = False

# Configuraci√≥n
PERSIST_DIR = os.getenv("CHROMA_PERSIST_DIRECTORY", "./data/chroma")
MODEL_PATH = os.getenv("MODEL_PATH", "./models/Phi-3-mini-4k-instruct-q4.gguf")
EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
MODEL_EMBED = EMBEDDING_MODEL_NAME
DISABLE_PRECOMPUTED = os.getenv("DISABLE_PRECOMPUTED", "false").lower() == "true"  # Hybrid: MockLLM primero, LLM despu√©s
NUM_THREADS = int(os.getenv("NUM_THREADS", "4"))

# Configuraci√≥n de Groq API
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
USE_GROQ_API = os.getenv("USE_GROQ_API", "true").lower() == "true"
GROQ_MODEL = os.getenv("GROQ_MODEL", "llama-3.1-8b-instant")


# Modelos de Pydantic para la API
class Message(BaseModel):
    """Mensaje en el historial de conversaci√≥n."""
    role: str  # 'user' o 'assistant'
    content: str


class QueryRequest(BaseModel):
    """Modelo para peticiones de consulta."""
    question: str
    history: List[Message] = []  # Historial de conversaci√≥n


class QueryResponse(BaseModel):
    """Modelo para respuestas de consulta."""
    answer: str
    sources: List[Any] = []  # Puede ser string o dict con metadata
    processing_time: float = 0.0
    cached: bool = False


class SmartCache:
    """Cache inteligente con TTL y l√≠mite de tama√±o."""
    def __init__(self, max_size: int = 1000, ttl: int = 3600):
        self.cache: OrderedDict = OrderedDict()
        self.max_size = max_size
        self.ttl = ttl
        self.hits = 0
        self.misses = 0
        self.lock = threading.Lock()
    
    def get(self, key: str) -> Optional[Dict[str, Any]]:
        """Obtener valor del cache si existe y no ha expirado."""
        with self.lock:
            if key in self.cache:
                value, timestamp = self.cache[key]
                if time.time() - timestamp < self.ttl:
                    self.hits += 1
                    # Mover al final (m√°s reciente)
                    self.cache.move_to_end(key)
                    return value
                else:
                    # Expir√≥, eliminar
                    del self.cache[key]
            self.misses += 1
            return None
    
    def set(self, key: str, value: Dict[str, Any]) -> None:
        """Guardar valor en cache."""
        with self.lock:
            if key in self.cache:
                self.cache.move_to_end(key)
            self.cache[key] = (value, time.time())
            # Limitar tama√±o del cache
            if len(self.cache) > self.max_size:
                self.cache.popitem(last=False)
    
    def clear(self) -> None:
        """Limpiar cache."""
        with self.lock:
            self.cache.clear()
    
    def stats(self) -> Dict[str, Any]:
        """Estad√≠sticas del cache."""
        total = self.hits + self.misses
        hit_rate = (self.hits / total * 100) if total > 0 else 0
        return {
            "size": len(self.cache),
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": f"{hit_rate:.1f}%"
        }


class PrecomputedResponses:
    """Respuestas precomputadas para consultas comunes."""
    def __init__(self):
        self.responses = {
            "pension": {
                "keywords": ["pensi√≥n", "alimentos", "manutenci√≥n", "pago", "hijo", "ex esposo", "ex esposa"],
                "answer": """Entiendo tu situaci√≥n con la pensi√≥n alimentaria. Te explico paso a paso qu√© hacer:

üèõÔ∏è **D√≥nde ir:**
‚Ä¢ Juzgado de Familia de tu circuito judicial
‚Ä¢ Defensa P√∫blica (gratuita si calificas econ√≥micamente)
‚Ä¢ PANI para orientaci√≥n adicional

üìã **Documentos necesarios:**
‚Ä¢ Acta de nacimiento del menor (original y copia)
‚Ä¢ Tu c√©dula de identidad
‚Ä¢ C√©dula del otro progenitor (si la tienes)
‚Ä¢ Comprobantes de gastos del menor
‚Ä¢ Tu comprobante de ingresos

üöÄ **Qu√© hacer:**
1. Presenta demanda en el Juzgado de Familia
2. Solicita medidas cautelares si hay urgencia
3. Pide retenci√≥n salarial autom√°tica
4. Si no paga, puede haber apremio corporal

‚ö° **Importante:** El incumplimiento puede llevar a retenci√≥n de salario, embargo de bienes e incluso prisi√≥n.

üí° **Consejo:** Lleva todo organizado y pregunta por "medidas provisionales" para pensi√≥n urgente.

---

**¬øEn qu√© m√°s puedo ayudarte?**
‚Ä¢ ¬øNecesit√°s que te explique m√°s sobre alguno de estos pasos?
‚Ä¢ ¬øQuer√©s saber qu√© hacer si el padre/madre vive en otro pa√≠s?
‚Ä¢ ¬øTe gustar√≠a conocer cu√°nto tiempo tarda cada etapa del proceso?
‚Ä¢ ¬øTen√©s dudas sobre los costos o si hay manera de hacerlo gratis?

Estoy aqu√≠ para ayudarte con lo que necesites. ¬°No dudes en preguntar! üòä"""
            },
            "duracion_conciliacion": {
                "keywords": ["cu√°nto dura", "duraci√≥n", "tiempo", "demora", "tarda", "cuanto tiempo"],
                "answer": """Una conciliaci√≥n generalmente dura:

‚è±Ô∏è **Duraci√≥n t√≠pica:**
‚Ä¢ **Primera sesi√≥n:** 1-2 horas
‚Ä¢ **Proceso completo:** 1-3 sesiones (dependiendo del caso)
‚Ä¢ **Plazo total:** Usualmente se resuelve en 1-2 meses

üìÖ **Factores que influyen:**
‚Ä¢ Complejidad del caso
‚Ä¢ Disponibilidad de las partes
‚Ä¢ Documentaci√≥n necesaria
‚Ä¢ Si hay acuerdo o no

‚úÖ **Ventajas vs juicio:**
‚Ä¢ Conciliaci√≥n: 1-2 meses
‚Ä¢ Juicio tradicional: 6 meses a 2+ a√±os

üèõÔ∏è **Tipos de conciliaci√≥n:**
‚Ä¢ **Pre-procesal:** Antes de juicio (m√°s r√°pida)
‚Ä¢ **Procesal:** Durante el juicio
‚Ä¢ **Judicial:** En el juzgado

üí° **Consejo:** La rapidez depende mucho de la actitud colaborativa de ambas partes.

----

**¬øTe puedo ayudar con algo m√°s?**
‚Ä¢ ¬øQuer√©s saber c√≥mo prepararte para una conciliaci√≥n?
‚Ä¢ ¬øNecesit√°s informaci√≥n sobre qu√© pasa si no hay acuerdo?
‚Ä¢ ¬øTe interesa conocer qu√© casos se pueden conciliar?
‚Ä¢ ¬øTen√©s dudas sobre los requisitos para iniciar?

Estoy aqu√≠ para ayudarte. üòä"""
            },
            "facilitador": {
                "keywords": ["facilitador judicial", "ser facilitador", "requisitos facilitador", "trabajo facilitador", "certificaci√≥n facilitador", "curso facilitador"],
                "answer": """Para ser Facilitador Judicial en Costa Rica, necesitas:

üìã **Requisitos:**
‚Ä¢ Ser costarricense o extranjero con residencia legal
‚Ä¢ Mayor de 25 a√±os
‚Ä¢ T√≠tulo universitario o experiencia comprobada
‚Ä¢ No tener antecedentes penales
‚Ä¢ Capacitaci√≥n certificada por el Poder Judicial

üìö **Capacitaci√≥n:**
‚Ä¢ Curso oficial del Poder Judicial
‚Ä¢ Temas: mediaci√≥n, conciliaci√≥n, t√©cnicas de facilitaci√≥n
‚Ä¢ Duraci√≥n: variable seg√∫n programa

üèõÔ∏è **D√≥nde informarte:**
‚Ä¢ Poder Judicial: 2295-3000
‚Ä¢ Direcci√≥n de Resoluci√≥n Alterna de Conflictos

üíº **Funciones:**
‚Ä¢ Facilitar procesos de conciliaci√≥n
‚Ä¢ Ayudar a las partes a llegar a acuerdos
‚Ä¢ Orientar sobre procedimientos

üí° **Consejo:** Contacta directamente al Poder Judicial para informaci√≥n sobre pr√≥ximas capacitaciones.

---

**¬øAlgo m√°s en lo que te pueda ayudar?**
‚Ä¢ ¬øQuer√©s saber m√°s sobre el proceso de capacitaci√≥n?
‚Ä¢ ¬øTe interesa conocer las funciones espec√≠ficas de un facilitador?
‚Ä¢ ¬øNecesit√°s informaci√≥n sobre d√≥nde dar el curso?
‚Ä¢ ¬øTen√©s dudas sobre los requisitos o documentos?

Estoy aqu√≠ para ayudarte. ¬°Segu√≠ preguntando! üìö"""
            },
            "proceso_conciliacion": {
                "keywords": ["c√≥mo funciona conciliaci√≥n", "proceso de conciliaci√≥n", "qu√© es conciliaci√≥n", "conciliaci√≥n judicial", "conciliar"],
                "answer": """La conciliaci√≥n es un proceso voluntario para resolver conflictos. Te explico c√≥mo funciona:

ü§ù **¬øQu√© es?**
Es un proceso donde un facilitador neutral ayuda a las partes a llegar a un acuerdo sin ir a juicio.

üìã **Pasos del proceso:**
1. **Solicitud:** Una o ambas partes piden la conciliaci√≥n
2. **Citaci√≥n:** Se notifica a la otra parte
3. **Sesi√≥n:** El facilitador modera el di√°logo
4. **Acuerdo:** Si hay acuerdo, se firma y tiene validez legal
5. **Sin acuerdo:** Se puede acudir a juicio

‚úÖ **Ventajas:**
‚Ä¢ M√°s r√°pido que un juicio
‚Ä¢ Menos costoso
‚Ä¢ Las partes mantienen el control
‚Ä¢ Acuerdos m√°s flexibles
‚Ä¢ Menos conflictivo

üèõÔ∏è **Casos que se pueden conciliar:**
‚Ä¢ Pensi√≥n alimentaria
‚Ä¢ Regulaci√≥n de visitas
‚Ä¢ Conflictos laborales (algunos)
‚Ä¢ Asuntos de familia
‚Ä¢ Conflictos vecinales

‚ö†Ô∏è **No se concilia:**
‚Ä¢ Delitos graves
‚Ä¢ Violencia dom√©stica
‚Ä¢ Derechos irrenunciables

üí° **Consejo:** La conciliaci√≥n funciona mejor cuando ambas partes quieren llegar a un acuerdo.

----

**¬øEn qu√© m√°s te puedo ayudar?**
‚Ä¢ ¬øNecesit√°s saber d√≥nde solicitar una conciliaci√≥n?
‚Ä¢ ¬øQuer√©s conocer qu√© documentos llevar?
‚Ä¢ ¬øTe interesa saber cu√°nto cuesta?
‚Ä¢ ¬øTen√©s dudas sobre si tu caso se puede conciliar?

Preguntame lo que necesites. üòä"""
            }
        }
    
    def find_match(self, question: str) -> Optional[str]:
        """Buscar respuesta precomputada."""
        question_lower = question.lower()
        for category, data in self.responses.items():
            if any(keyword in question_lower for keyword in data["keywords"]):
                return data["answer"]
        return None


class LocalLLM:
    """LLM local basado en llama.cpp para modelos GGUF (CPU/GPU)."""
    def __init__(self, model_path: str, n_ctx: int = 4096, n_threads: int = 4, n_gpu_layers: int = 0):
        self.model_path = model_path
        self.n_ctx = n_ctx
        self.n_threads = n_threads
        self.n_gpu_layers = n_gpu_layers
        self._llama: Optional[Llama] = None

    def _ensure_loaded(self) -> None:
        if self._llama is None:
            self._llama = Llama(
                model_path=self.model_path,
                n_ctx=self.n_ctx,
                n_threads=self.n_threads,
                n_gpu_layers=self.n_gpu_layers,
                verbose=False,
            )

    async def generate_async(self, prompt: str) -> str:
        loop = asyncio.get_event_loop()

        def _run() -> str:
            self._ensure_loaded()
            assert self._llama is not None
            out = self._llama.create_completion(
                prompt=prompt,
                max_tokens=400,  # Reducido para respuestas m√°s r√°pidas
                temperature=0.7,
                top_p=0.9,
                top_k=40,
                repeat_penalty=1.1,
                stop=["\n\nCONTEXTO:", "\n\nPREGUNTA:", "###", "</s>"]
            )
            return out["choices"][0]["text"].strip()

        return await loop.run_in_executor(None, _run)


# LLM usando Groq API (ultra-r√°pido y gratuito)
class GroqLLM:
    """LLM usando Groq API en la nube - 1-2 segundos por respuesta."""
    def __init__(self, api_key: str, model: str = "llama-3.1-8b-instant"):
        if not api_key:
            raise ValueError("GROQ_API_KEY no est√° configurada. Obt√©n una gratis en: https://console.groq.com")
        self.client = Groq(api_key=api_key)
        self.model = model
        self.name = f"Groq {model}"
    
    async def generate_async(self, prompt: str) -> str:
        """Generaci√≥n as√≠ncrona ultra-r√°pida con Groq."""
        loop = asyncio.get_event_loop()
        
        def _run() -> str:
            try:
                completion = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": "Sos un facilitador judicial de Costa Rica. Respond√© de forma clara, pr√°ctica y amable en espa√±ol."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    temperature=0.7,
                    max_tokens=500,
                    top_p=0.9,
                    stream=False
                )
                return completion.choices[0].message.content.strip()
            except Exception as e:
                logger.error(f"Error en Groq API: {e}")
                return f"Lo siento, hubo un error al procesar tu pregunta. Por favor intenta de nuevo."
        
        return await loop.run_in_executor(None, _run)


# LLM simulado optimizado
class MockLLM:
    def __init__(self):
        self.name = "Optimized Mock LLM"
        self.response_cache = {}
    
    async def generate_async(self, prompt: str) -> str:
        """Generaci√≥n as√≠ncrona simulada con an√°lisis inteligente."""
        # Simular procesamiento m√°s realista para preguntas complejas
        await asyncio.sleep(0.2)  # 200ms para dar sensaci√≥n de an√°lisis
        
        prompt_lower = prompt.lower()
        
        # Detectar si es una pregunta compleja que lleg√≥ hasta aqu√≠
        if "contexto:" in prompt_lower:
            # Es una pregunta que pas√≥ por RAG, intentar respuesta m√°s inteligente
            return await self._generate_contextual_response(prompt)
        
        # Respuestas para preguntas que no encontraron contexto
        return await self._generate_fallback_response(prompt)
    
    def _add_proactive_followup(self, base_response: str, topic: str) -> str:
        """Agrega seguimiento proactivo al final de la respuesta."""
        followup_templates = {
            "pensi√≥n": """

---

**¬øEn qu√© m√°s puedo ayudarte?**
‚Ä¢ ¬øNecesit√°s que te explique m√°s sobre alguno de estos pasos?
‚Ä¢ ¬øQuer√©s saber qu√© hacer si el padre/madre vive en otro pa√≠s?
‚Ä¢ ¬øTe gustar√≠a conocer cu√°nto tiempo tarda cada etapa del proceso?
‚Ä¢ ¬øTen√©s dudas sobre los costos o si hay manera de hacerlo gratis?

Estoy aqu√≠ para ayudarte con lo que necesites. ¬°No dudes en preguntar! üòä""",
            "laboral": """

---

**¬øTe puedo ayudar con algo m√°s?**
‚Ä¢ ¬øQuer√©s saber qu√© hacer si te despiden durante este proceso?
‚Ä¢ ¬øNecesit√°s informaci√≥n sobre indemnizaci√≥n o liquidaci√≥n?
‚Ä¢ ¬øTe gustar√≠a saber c√≥mo presentar una denuncia formal?
‚Ä¢ ¬øTen√©s preguntas sobre tus derechos espec√≠ficos como trabajador?

Estoy aqu√≠ para lo que necesites. ¬°Pregunt√° con confianza! üí™""",
            "facilitador": """

---

**¬øAlgo m√°s en lo que te pueda ayudar?**
‚Ä¢ ¬øQuer√©s saber m√°s sobre el proceso de capacitaci√≥n?
‚Ä¢ ¬øTe interesa conocer las funciones espec√≠ficas de un facilitador?
‚Ä¢ ¬øNecesit√°s informaci√≥n sobre d√≥nde dar el curso?
‚Ä¢ ¬øTen√©s dudas sobre los requisitos o documentos?

Estoy aqu√≠ para ayudarte. ¬°Segu√≠ preguntando! üìö""",
            "general": """

---

**¬øNecesit√°s m√°s informaci√≥n?**
‚Ä¢ ¬øQuer√©s que te aclare alg√∫n punto espec√≠fico?
‚Ä¢ ¬øTe gustar√≠a saber sobre los costos del procedimiento?
‚Ä¢ ¬øNecesit√°s orientaci√≥n sobre los pr√≥ximos pasos?
‚Ä¢ ¬øTen√©s otra pregunta relacionada con tu situaci√≥n?

Con gusto te ayudo con lo que necesites. ¬°Pregunt√° sin pena! üòä"""
        }
        
        # Seleccionar el seguimiento apropiado
        followup = followup_templates.get(topic, followup_templates["general"])
        return base_response + followup
    
    async def _generate_contextual_response(self, prompt: str) -> str:
        """Genera respuesta basada en contexto de documentos."""
        prompt_lower = prompt.lower()
        
        # Analizar el tipo de consulta y extraer ubicaci√≥n si est√° presente
        location_mentioned = None
        costa_rica_locations = {
            "san jos√©": "San Jos√©", "cartago": "Cartago", "alajuela": "Alajuela", 
            "heredia": "Heredia", "puntarenas": "Puntarenas", "guanacaste": "Guanacaste",
            "lim√≥n": "Lim√≥n", "liberia": "Liberia", "p√©rez zeled√≥n": "P√©rez Zeled√≥n",
            "desamparados": "Desamparados", "escaz√∫": "Escaz√∫", "goicoechea": "Goicoechea"
        }
        
        for location, proper_name in costa_rica_locations.items():
            if location in prompt_lower:
                location_mentioned = proper_name
                break
        
        if any(word in prompt_lower for word in ["pensi√≥n", "alimentos", "manutenci√≥n", "hijo", "hija"]):
            if location_mentioned:
                response = f"""Entiendo tu situaci√≥n con la pensi√≥n alimentaria. Como sos de {location_mentioned}, te explico exactamente d√≥nde ir:

üèõÔ∏è **Juzgado de Familia de {location_mentioned}**
üìç Ubicado en el Edificio de Tribunales de Justicia de {location_mentioned}
üìû Tel√©fono: Poder Judicial centralizado 2295-3000 (pedir comunicar con pensiones alimentarias)
‚è∞ Horario: Lunes a viernes, 8:00 AM - 4:00 PM

üÜì **Defensa P√∫blica (GRATUITA)**
üìç En el mismo edificio de tribunales
üí° Pueden llevarte el caso completo sin costo si calificas econ√≥micamente

üë∂ **PANI - Apoyo adicional (si es para menores)**
üìû Oficina local del PANI en {location_mentioned}
üéØ Te pueden dar orientaci√≥n legal gratuita y apoyo durante el proceso

üìã **Documentos que DEBES llevar:**
‚Ä¢ ‚úÖ Tu c√©dula de identidad
‚Ä¢ ‚úÖ Acta de nacimiento del menor (original y copia)
‚Ä¢ ‚úÖ Datos completos del padre/madre (nombre, c√©dula, direcci√≥n, trabajo)
‚Ä¢ ‚úÖ Comprobantes de gastos del menor (alimentaci√≥n, educaci√≥n, salud, ropa)
‚Ä¢ ‚úÖ Tu comprobante de ingresos (si trabajas)
‚Ä¢ ‚úÖ Cualquier resoluci√≥n previa sobre pensi√≥n (si existe)

üöÄ **Qu√© pod√©s hacer ah√≠:**
‚Ä¢ Presentar demanda de pensi√≥n alimentaria
‚Ä¢ Solicitar aumento o rebajo de pensi√≥n existente
‚Ä¢ Denunciar incumplimiento de pago
‚Ä¢ Pedir retenci√≥n salarial autom√°tica
‚Ä¢ Solicitar apremio corporal si no paga

‚ö° **IMPORTANTE:** Si hay incumplimiento, pueden retener salario, embargar bienes, e incluso ordenar prisi√≥n. ¬°No esperes m√°s!

üí° **Consejo:** Lleva todo organizado y pregunta por "medidas provisionales" si necesitas pensi√≥n urgente mientras se resuelve el caso."""
                return self._add_proactive_followup(response, "pensi√≥n")
            else:
                response = """Te entiendo perfectamente, la pensi√≥n alimentaria es un derecho fundamental de los menores. Te explico paso a paso:

üéØ **PASO 1: Eval√∫a tu situaci√≥n**
‚Ä¢ ¬øEl padre/madre reconoce al menor legalmente?
‚Ä¢ ¬øHay acuerdo previo o necesitas demanda judicial?
‚Ä¢ ¬øEs urgente? (el menor no tiene lo b√°sico)

üèõÔ∏è **PASO 2: D√≥nde ir seg√∫n tu caso**

**Si hay urgencia extrema:**
‚Ä¢ üö® Juzgado de Familia - Medidas Cautelares
‚Ä¢ üìû Solicita cita: Poder Judicial (centralizada)
‚Ä¢ ‚ö° Pueden fijar pensi√≥n provisional en d√≠as

**Para demanda formal:**
‚Ä¢ üìç Juzgado de Familia de tu circuito judicial
‚Ä¢ üÜì Defensa P√∫blica (gratuita si calificas)
‚Ä¢ üíº Abogado privado (si prefieres)

üìã **PASO 3: Documentos que DEBES llevar**
‚Ä¢ ‚úÖ Acta de nacimiento del menor (original y copia)
‚Ä¢ ‚úÖ Tu c√©dula de identidad
‚Ä¢ ‚úÖ C√©dula del otro progenitor (si la tienes)
‚Ä¢ ‚úÖ Comprobantes de gastos del menor:
  - Recibos m√©dicos, medicinas
  - Facturas de alimentaci√≥n
  - Gastos de educaci√≥n, ropa
  - Recibo de guarder√≠a/cuidado

üí∞ **PASO 4: C√≥mo se calcula el monto**
‚Ä¢ Ingresos del deudor alimentario
‚Ä¢ Necesidades b√°sicas del menor
‚Ä¢ N√∫mero de hijos que debe mantener
‚Ä¢ Capacidad econ√≥mica de ambos padres

‚è∞ **PLAZOS IMPORTANTES:**
‚Ä¢ No hay plazo para solicitar pensi√≥n
‚Ä¢ Medidas provisionales: 1-2 semanas
‚Ä¢ Proceso completo: 2-6 meses

üÜò **Si no paga la pensi√≥n:**
‚Ä¢ Apremio corporal (puede ir preso)
‚Ä¢ Embargo de salario/bienes
‚Ä¢ Retenci√≥n de licencia de conducir

üí° **CONSEJO:** Lleva todo organizado y no tengas miedo de preguntar en el juzgado. Es tu derecho y el del menor."""
                return self._add_proactive_followup(response, "pensi√≥n")
        
        elif any(word in prompt_lower for word in ["laboral", "trabajo", "empleador", "jefe", "salario"]):
            if location_mentioned:
                return f"""Entiendo tu situaci√≥n laboral. Como sos de {location_mentioned}, te explico exactamente d√≥nde ir:

üìã **PASO 1: Documenta TODO ahora mismo**
‚Ä¢ Guarda correos, mensajes, horarios de trabajo
‚Ä¢ Anota fechas exactas, horas y testigos
‚Ä¢ Fotograf√≠a condiciones de trabajo si es necesario
‚Ä¢ Conserva todos los recibos de pago

üè¢ **Direcci√≥n Regional de Trabajo de {location_mentioned}**
üìç Ministerio de Trabajo y Seguridad Social - Oficina {location_mentioned}
üìû L√≠nea gratuita: 800-TRABAJO (800-8722246)
‚è∞ Horario: Lunes a viernes, 7:00 AM - 4:00 PM
üÜì Servicios completamente GRATUITOS

üö® **Para casos URGENTES (salarios no pagados):**
‚Ä¢ Ve directamente a la oficina sin cita
‚Ä¢ Solicita "mediaci√≥n laboral inmediata"
‚Ä¢ Pueden llamar a tu empleador ese mismo d√≠a
‚Ä¢ Si no resuelve, pasan a inspecci√≥n formal

‚öñÔ∏è **Juzgado de Trabajo de {location_mentioned}**
üìç Edificio de Tribunales de Justicia
üéØ Para demandas por despido injustificado
‚ö° CR√çTICO: Solo tienes 30 d√≠as desde el despido

üìÑ **Documentos espec√≠ficos que necesitas:**
‚Ä¢ ‚úÖ Tu c√©dula de identidad
‚Ä¢ ‚úÖ Contrato de trabajo (si lo tienes)
‚Ä¢ ‚úÖ √öltimos 3 recibos de pago
‚Ä¢ ‚úÖ Carta de despido o √∫ltima comunicaci√≥n del empleador
‚Ä¢ ‚úÖ Todas las pruebas del problema (fotos, mensajes, testigos)

üí° **ESTRATEGIA:** Ve primero al Ministerio de Trabajo. Si no resuelven en 15 d√≠as, entonces al juzgado. ¬°El tiempo corre en tu contra!"""
            else:
                return """Entiendo tu situaci√≥n laboral. Te gu√≠o paso a paso:

üìã **PASO 1: Documenta todo**
‚Ä¢ Guarda correos, mensajes, horarios de trabajo
‚Ä¢ Anota fechas, horas y testigos de incidentes
‚Ä¢ Fotograf√≠a condiciones de trabajo si es necesario
‚Ä¢ Conserva recibos de pago o comprobantes

üè¢ **PASO 2: D√≥nde acudir seg√∫n tu problema**

**Para salarios no pagados o atrasos:**
‚Ä¢ üìû Ministerio de Trabajo: 800-TRABAJO (800-8722246)
‚Ä¢ üìç Direcci√≥n Regional m√°s cercana
‚Ä¢ ‚è∞ Horario: 7:00 AM - 4:00 PM, lunes a viernes

**Para despidos injustificados:**
‚Ä¢ üèõÔ∏è Juzgado de Trabajo de tu zona
‚Ä¢ üìÑ Presenta demanda dentro de 30 d√≠as
‚Ä¢ üíº Considera contratar abogado laboralista

**Para acoso o discriminaci√≥n:**
‚Ä¢ üö® Inspecci√≥n de Trabajo (denuncia inmediata)
‚Ä¢ üìû L√≠nea gratuita: 800-TRABAJO
‚Ä¢ üìß Tambi√©n puedes denunciar en l√≠nea

üìù **PASO 3: Qu√© documentos necesitas**
‚Ä¢ C√©dula de identidad
‚Ä¢ Contrato de trabajo (si lo tienes)
‚Ä¢ √öltimos 3 recibos de pago
‚Ä¢ Certificaci√≥n laboral o carta de despido
‚Ä¢ Pruebas del problema espec√≠fico

üí° **IMPORTANTE:** No esperes, muchos derechos laborales tienen plazos espec√≠ficos para reclamar."""
        
        elif any(word in prompt_lower for word in ["facilitador", "conciliaci√≥n", "mediaci√≥n"]):
            return """Excelente consulta sobre facilitaci√≥n judicial:

üìö **Marco normativo:**
‚Ä¢ La facilitaci√≥n judicial est√° regulada por el C√≥digo Procesal Civil
‚Ä¢ Requiere certificaci√≥n del Consejo Superior de la Judicatura
‚Ä¢ Es un mecanismo alternativo de resoluci√≥n de conflictos

üéØ **Proceso t√≠pico:**
‚Ä¢ Admisi√≥n de la solicitud
‚Ä¢ Designaci√≥n del facilitador
‚Ä¢ Audiencias de facilitaci√≥n
‚Ä¢ Homologaci√≥n del acuerdo (si se alcanza)

üí° **Ventajas:** Proceso m√°s r√°pido, menos formal y con mayor control de las partes sobre el resultado."""
        
        else:
            return """Bas√°ndome en la informaci√≥n disponible, te oriento paso a paso:

üìã **PASO 1: Identifica tu situaci√≥n espec√≠fica**
‚Ä¢ ¬øEs un problema civil, laboral, familiar o penal?
‚Ä¢ ¬øQu√© resultado espec√≠fico buscas obtener?
‚Ä¢ ¬øHay urgencia en tu caso?

üèõÔ∏è **PASO 2: Instituciones seg√∫n tu caso**

**Problemas Familiares (pensi√≥n, divorcio, custodia):**
üìç Juzgado de Familia de tu circuito
üÜì Defensa P√∫blica disponible
üìû Poder Judicial: 2295-3000

**Problemas Laborales (salarios, despidos):**
üìç Ministerio de Trabajo: 800-TRABAJO (800-8722246)
üìç Juzgados de Trabajo para demandas

**Problemas Civiles (contratos, deudas):**
üìç Juzgados Civiles
üíº Considera abogado especializado

**Violencia o delitos:**
üìç Ministerio P√∫blico (Fiscal√≠a)
üö® OIJ para denuncias: 800-8000645

üìÑ **PASO 3: Documentos b√°sicos siempre necesarios**
‚Ä¢ ‚úÖ C√©dula de identidad
‚Ä¢ ‚úÖ Documentos relacionados al problema
‚Ä¢ ‚úÖ Pruebas (contratos, mensajes, testigos)
‚Ä¢ ‚úÖ Comprobantes de gastos si aplica

üí° **IMPORTANTE:** Si no est√°s seguro, ve primero a la Defensa P√∫blica (gratuita) para orientaci√≥n inicial. Est√°n en todos los circuitos judiciales."""
    
    async def _generate_fallback_response(self, prompt: str) -> str:
        """Respuesta cuando no hay contexto suficiente."""
        return """Lo siento, necesito m√°s informaci√≥n espec√≠fica para ayudarte mejor.

ü§î **Para brindarte una respuesta m√°s precisa, podr√≠as:**
‚Ä¢ Especificar tu situaci√≥n particular
‚Ä¢ Indicar el tipo de procedimiento que te interesa
‚Ä¢ Mencionar si es sobre familia, trabajo, civil, etc.

üìö **Puedo ayudarte con temas como:**
‚Ä¢ Pensi√≥n alimentaria y derecho de familia
‚Ä¢ Problemas laborales y derechos del trabajador
‚Ä¢ Facilitaci√≥n judicial y conciliaci√≥n
‚Ä¢ Procedimientos civiles b√°sicos

¬°Reformula tu pregunta con m√°s detalles y te ayudo mejor! üòä"""

# Bot optimizado
class JudicialBot:
    def __init__(self, persist_dir: str):
        self.persist_dir = persist_dir
        self.vectordb = None
        self.llm: Any = MockLLM()
        self.cache = SmartCache()
        self.precomputed = PrecomputedResponses()
        self.executor = ThreadPoolExecutor(max_workers=4)
        self.embedder = None
        # Gate para usar o no precomputadas segun env
        self.use_precomputed: bool = not DISABLE_PRECOMPUTED
        
    async def initialize(self):
        """Inicializaci√≥n as√≠ncrona."""
        try:
            logger.info("üöÄ Inicializando sistema...")
            
            # Cargar embeddings en paralelo
            loop = asyncio.get_event_loop()
            self.embedder = await loop.run_in_executor(
                self.executor, 
                lambda: SentenceTransformerEmbeddings(model_name=MODEL_EMBED)
            )
            
            # Seleccionar modelo de lenguaje (prioridad: Groq API > Local > MockLLM)
            if USE_GROQ_API and _GROQ_AVAILABLE and GROQ_API_KEY:
                try:
                    logger.info(f"üöÄ Usando Groq API: {GROQ_MODEL} (ultra-r√°pido)")
                    self.llm = GroqLLM(api_key=GROQ_API_KEY, model=GROQ_MODEL)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error configurando Groq: {e}. Usando MockLLM")
                    self.llm = MockLLM()
            elif _LLAMA_AVAILABLE and os.path.exists(MODEL_PATH):
                logger.info(f"üß† Usando modelo local GGUF: {MODEL_PATH}")
                n_gpu_layers = int(os.getenv("N_GPU_LAYERS", "-1"))
                n_ctx = int(os.getenv("N_CTX", "2048"))
                self.llm = LocalLLM(model_path=MODEL_PATH, n_ctx=n_ctx, n_threads=NUM_THREADS, n_gpu_layers=n_gpu_layers)
            else:
                logger.warning("‚ö†Ô∏è Usando MockLLM de respaldo (configura GROQ_API_KEY para m√°s flexibilidad)")

            # Cargar base de datos vectorial
            if os.path.exists(self.persist_dir):
                self.vectordb = await loop.run_in_executor(
                    self.executor,
                    lambda: Chroma(
                        persist_directory=self.persist_dir,
                        embedding_function=self.embedder
                    )
                )
                
                doc_count = await loop.run_in_executor(
                    self.executor,
                    lambda: self.vectordb._collection.count()
                )
                
                logger.info(f"‚úÖ Sistema inicializado con {doc_count} documentos")
            else:
                logger.warning("‚ö†Ô∏è Base de datos vectorial no encontrada, usando solo respuestas precomputadas")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error en inicializaci√≥n: {e}")
            return False
    
    async def search_documents_async(self, query: str, k: int = 2) -> List[Document]:
        """B√∫squeda as√≠ncrona de documentos."""
        if not self.vectordb:
            return []
        
        try:
            loop = asyncio.get_event_loop()
            results = await loop.run_in_executor(
                self.executor,
                lambda: self.vectordb.similarity_search(query, k=k)
            )
            return results
        except Exception as e:
            logger.error(f"Error en b√∫squeda: {e}")
            return []
    
    def clean_answer(self, raw_text: str) -> str:
        """Limpia metainstrucciones de la respuesta."""
        if not raw_text:
            return ""
        
        lines = raw_text.splitlines()
        cleaned_lines = []
        
        # Construir patrones prohibidos, respetando ALLOW_CONTACTS
        redact_contacts = os.getenv("ALLOW_CONTACTS", "false").lower() != "true"
        forbidden_patterns = [
            r"^\s*fuente\s*:",
            r"^\s*fuentes\s*:",
            r"^\s*tiempo\s*:",
            r"estructura\s+sugerida",
            r"si no hay provincia",
            r"^\s*contexto\s*:",
            r"^\s*pregunta\s*:",
            r"^\s*respuesta\s*:",
            r"ahora responde",
            r"respuesta estructurada"
        ]
        if redact_contacts:
            forbidden_patterns.append(r"^\s*tel")
        
        forbidden_regexes = [re.compile(pat, re.IGNORECASE) for pat in forbidden_patterns]
        
        for line in lines:
            if any(rx.search(line) for rx in forbidden_regexes):
                continue
            # Evitar placeholders obvios
            if "XXXX" in line:
                continue
            cleaned_lines.append(line)
        
        cleaned = "\n".join(cleaned_lines).strip()
        cleaned = re.sub(r"\n{3,}", "\n\n", cleaned)
        
        # Filtrar n√∫meros telef√≥nicos (seg√∫n variable de entorno)
        if redact_contacts:
            phone_like = re.compile(r"(?:\+?\d[\d\s().-]{7,}\d)")
            cleaned = phone_like.sub("[consultar directorio oficial]", cleaned)
        
        return cleaned
    
    async def ask_async(self, question: str, history: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Procesamiento as√≠ncrono ultra-r√°pido de preguntas con contexto conversacional."""
        start_time = time.time()
        if history is None:
            history = []
        
        try:
            # 1. Verificar cache (m√°s r√°pido)
            cached_response = self.cache.get(question)
            if cached_response:
                cached_response['processing_time'] = time.time() - start_time
                return cached_response
            
            # 2. Verificar respuestas precomputadas (opcional)
            if self.use_precomputed:
                precomputed_answer = self.precomputed.find_match(question)
                if precomputed_answer:
                    response = {
                        "answer": precomputed_answer,
                        "sources": [],
                        "processing_time": time.time() - start_time,
                        "cached": False
                    }
                    # Guardar en cache
                    self.cache.set(question, response)
                    return response
            
            # 3. Procesamiento con RAG (solo si es necesario)
            # Intensificar retrieval para respuestas m√°s ricas
            relevant_docs = await self.search_documents_async(question, k=4)
            
            # Crear contexto limitado
            context = ""
            sources = []
            
            for doc in relevant_docs[:2]:
                filename = doc.metadata.get('filename', 'Documento')
                context += f"\n--- {filename} ---\n"
                context += (doc.page_content[:400] if doc.page_content else "") + "\n"
                
                sources.append({
                    "filename": filename,
                    "content": doc.page_content[:150] + "...",
                    "source": doc.metadata.get("source", "Desconocido")
                })
            
            # Detectar ubicaci√≥n simple en la pregunta para orientar mejor
            detected_location = None
            for loc in [
                "san jos√©", "cartago", "alajuela", "heredia", "puntarenas",
                "guanacaste", "lim√≥n", "liberia", "p√©rez zeled√≥n", "desamparados",
                "escaz√∫", "goicoechea"
            ]:
                if loc in question.lower():
                    detected_location = loc.title()
                    break

            location_hint = f"Ubicaci√≥n detectada: {detected_location}. Adapta la gu√≠a a esa localidad, menciona oficinas locales y tel√©fonos oficiales si se permiten." if detected_location else ""

            # Agregar historial de conversaci√≥n si existe
            conversation_context = ""
            if history and len(history) > 0:
                conversation_context = "\n\n**CONVERSACI√ìN PREVIA:**\n"
                for msg in history[-4:]:  # Solo las √∫ltimas 4 interacciones
                    role_label = "Usuario" if msg.get("role") == "user" else "T√∫ (Facilitador)"
                    conversation_context += f"{role_label}: {msg.get('content', '')}\n"
                conversation_context += "\nConsidera este contexto para dar una respuesta m√°s personalizada y coherente.\n"

            # Crear prompt simplificado para respuestas m√°s r√°pidas
            prompt = f"""Sos un facilitador judicial de Costa Rica. Respond√© de forma clara, pr√°ctica y amable en espa√±ol.

Contexto legal:
{context}

Pregunta: {question}

Respuesta (clara, con pasos si aplica, y al final ofrec√© ayuda adicional):"""
            
            # Generar respuesta as√≠ncrona
            answer_raw = await self.llm.generate_async(prompt)
            answer = self.clean_answer(answer_raw)
            
            response = {
                "answer": answer,
                "sources": sources,
                "processing_time": time.time() - start_time,
                "cached": False
            }
            
            # Guardar en cache
            self.cache.set(question, response)
            
            logger.info(f"‚úÖ Respuesta generada en {response['processing_time']:.3f}s")
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando pregunta: {e}")
            return {
                "answer": "Disculpa, hubo un error t√©cnico. Por favor intenta de nuevo en un momento.",
                "sources": [],
                "processing_time": time.time() - start_time,
                "cached": False
            }

# Instancia global del bot
bot = JudicialBot(PERSIST_DIR)

# Configuraci√≥n de la aplicaci√≥n
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("üöÄ Iniciando API...")
    success = await bot.initialize()
    if not success:
        logger.error("‚ùå Error en inicializaci√≥n")
    yield
    # Shutdown
    logger.info("üëã Cerrando API...")

app = FastAPI(
    title="Bot de Facilitadores Judiciales",
    description="API optimizada para consultas judiciales con respuestas r√°pidas y amables",
    version="2.0.0",
    lifespan=lifespan
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health")
async def health_check():
    """Verificaci√≥n de salud del sistema."""
    cache_stats = bot.cache.stats()
    return {
        "status": "healthy",
        "version": "2.0.0",
        "timestamp": datetime.now().isoformat(),
        "cache_stats": cache_stats,
        "features": [
            "Cache inteligente",
            "Respuestas precomputadas", 
            "Procesamiento as√≠ncrono",
            "Operaciones paralelas",
            "Limpieza de respuestas"
        ]
    }

@app.post("/ask", response_model=QueryResponse)
async def ask_question(request: QueryRequest):
    """Endpoint principal para preguntas con respuestas optimizadas."""
    if not request.question.strip():
        raise HTTPException(status_code=400, detail="La pregunta no puede estar vac√≠a")
    
    # Convertir history de Message a dict si es necesario
    history_dicts = [msg.dict() if hasattr(msg, 'dict') else msg for msg in request.history]
    response = await bot.ask_async(request.question, history=history_dicts)
    return QueryResponse(**response)

@app.post("/ask/stream")
async def ask_question_stream(request: QueryRequest):
    """Endpoint con respuesta streaming para percepci√≥n de velocidad."""
    if not request.question.strip():
        raise HTTPException(status_code=400, detail="La pregunta no puede estar vac√≠a")
    
    async def generate_stream():
        # Obtener respuesta completa con historial
        history_dicts = [msg.dict() if hasattr(msg, 'dict') else msg for msg in request.history]
        response = await bot.ask_async(request.question, history=history_dicts)
        answer = response["answer"]
        
        # Simular streaming por palabras para percepci√≥n de velocidad
        words = answer.split()
        for i, word in enumerate(words):
            chunk = {
                "word": word,
                "is_final": i == len(words) - 1,
                "processing_time": response["processing_time"],
                "cached": response["cached"]
            }
            yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
            await asyncio.sleep(0.05)  # 50ms entre palabras
        
        # Enviar fuentes al final
        if response["sources"]:
            sources_chunk = {
                "sources": response["sources"],
                "is_sources": True
            }
            yield f"data: {json.dumps(sources_chunk, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/plain",
        headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
    )

@app.get("/stats")
async def get_stats():
    """Estad√≠sticas del sistema."""
    return {
        "cache_stats": bot.cache.stats(),
        "precomputed_responses": len(bot.precomputed.responses),
        "system_status": "optimal"
    }

@app.get("/documents")
async def get_documents():
    """Obtiene informaci√≥n sobre los documentos cargados."""
    total_docs = 0
    sample_docs = []
    
    try:
        if bot.vectordb:
            # Obtener conteo total de documentos
            collection = bot.vectordb._collection
            total_docs = collection.count()
            
            # Obtener muestra de documentos (primeros 5)
            if total_docs > 0:
                results = collection.get(limit=5)
                if results and 'documents' in results:
                    sample_docs = [
                        {
                            "content": doc[:200] + "..." if len(doc) > 200 else doc,
                            "id": results['ids'][i] if 'ids' in results else str(i)
                        }
                        for i, doc in enumerate(results['documents'])
                    ]
        
        return {
            "total_documents": total_docs,
            "sample_documents": sample_docs,
            "vector_db_status": "active" if bot.vectordb else "inactive"
        }
    except Exception as e:
        logger.error(f"Error obteniendo documentos: {e}")
        return {
            "total_documents": 0,
            "sample_documents": [],
            "vector_db_status": "error",
            "error": str(e)
        }

@app.post("/clear-cache")
async def clear_cache():
    """Limpia el cache del sistema."""
    bot.cache.clear()
    return {"message": "Cache limpiado exitosamente"}

if __name__ == "__main__":
    uvicorn.run(
        "api:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        workers=1,
        loop="asyncio",
        log_level="info"
    )
