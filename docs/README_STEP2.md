# PASO 2 - Ingesta de Documentos y Generaci√≥n de Embeddings

## Objetivo
Procesar documentos PDF, DOCX y TXT, fragmentarlos en chunks y generar embeddings para crear una base de datos vectorial con ChromaDB.

## Archivos generados
- `ingest.py` - Script principal de ingesta
- `data/docs/` - Carpeta con documentos de ejemplo
- `data/chroma/` - Base de datos vectorial (se crea autom√°ticamente)
- `README_STEP2.md` - Este archivo de instrucciones

## Documentos de ejemplo incluidos
- `ejemplo_procedimiento.txt` - Procedimiento de conciliaci√≥n judicial
- `guia_facilitador.txt` - Gu√≠a para facilitadores judiciales
- `marco_legal.txt` - Marco legal de la facilitaci√≥n judicial

## Instrucciones de ejecuci√≥n

### 1. Activar entorno virtual
```bash
source venv/bin/activate
```

### 2. Configurar variables de entorno (opcional)
```bash
export DATA_DIR=./data/docs
export VECTOR_DB_DIR=./data/chroma
```

### 3. Ejecutar ingesta de documentos
```bash
python ingest.py
```

### 4. Verificar resultados
```bash
# Verificar que se cre√≥ la base de datos
ls -la data/chroma/

# Deber√≠as ver archivos como:
# - chroma.sqlite3
# - index/
# - collection_metadata.json
```

## Salida esperada

El script mostrar√° logs como:
```
2024-01-XX XX:XX:XX - INFO - üöÄ Iniciando ingesta de documentos para Facilitadores Judiciales
2024-01-XX XX:XX:XX - INFO - Encontrados 3 archivos para procesar
2024-01-XX XX:XX:XX - INFO - Procesando: ejemplo_procedimiento.txt
2024-01-XX XX:XX:XX - INFO - ‚úÖ ejemplo_procedimiento.txt: 1 p√°ginas cargadas
2024-01-XX XX:XX:XX - INFO - Fragmentando documentos...
2024-01-XX XX:XX:XX - INFO - Documentos fragmentados: 15 chunks
2024-01-XX XX:XX:XX - INFO - Generando embeddings...
2024-01-XX XX:XX:XX - INFO - Modelo de embeddings: all-MiniLM-L6-v2
2024-01-XX XX:XX:XX - INFO - ‚úÖ Base de datos vectorial creada con 15 documentos
2024-01-XX XX:XX:XX - INFO - Probando recuperaci√≥n con consulta: 'procedimiento judicial'
2024-01-XX XX:XX:XX - INFO - Encontrados 3 documentos relevantes:
2024-01-XX XX:XX:XX - INFO - ‚úÖ Ingesta completada exitosamente!
```

## Soluci√≥n de problemas

### Error: "No module named 'unstructured'"
```bash
pip install "unstructured[local-inference]"
```

### Error: "No module named 'sentence_transformers'"
```bash
pip install sentence-transformers
```

### Error: "ChromaDB not found"
```bash
pip install chromadb
```

### Error de memoria al procesar PDFs grandes
```bash
# Procesar archivos m√°s peque√±os o usar un modelo de embeddings m√°s ligero
export MODEL_EMBED="all-MiniLM-L6-v2"
```

## Agregar nuevos documentos

1. Coloca archivos .txt, .pdf o .docx en `data/docs/`
2. Ejecuta `python ingest.py` nuevamente
3. Los nuevos documentos se agregar√°n a la base de datos existente

## Verificar la base de datos

Puedes verificar que la ingesta funcion√≥ correctamente:

```python
# Script de verificaci√≥n r√°pida
from langchain.vectorstores import Chroma
from langchain.embeddings import SentenceTransformerEmbeddings

# Cargar la base de datos
vectordb = Chroma(persist_directory="./data/chroma")

# Contar documentos
print(f"Documentos en la base: {vectordb._collection.count()}")

# Buscar documentos
results = vectordb.similarity_search("conciliaci√≥n", k=3)
for i, doc in enumerate(results, 1):
    print(f"{i}. {doc.metadata.get('filename')}: {doc.page_content[:100]}...")
```

## Pr√≥ximos pasos

Una vez completado este paso:
1. Verifica que no hay errores en los logs
2. Confirma que se cre√≥ la carpeta `data/chroma/` con archivos
3. Escribe `continuar` para proceder al **PASO 3** (Pipeline de recuperaci√≥n RAG)

## Configuraci√≥n avanzada

### Cambiar modelo de embeddings
Edita `ingest.py` y modifica la variable `MODEL_EMBED`:
```python
MODEL_EMBED = "all-mpnet-base-v2"  # Modelo m√°s grande y preciso
# o
MODEL_EMBED = "paraphrase-multilingual-MiniLM-L12-v2"  # Soporte multiling√ºe
```

### Ajustar tama√±o de chunks
Modifica las variables en `ingest.py`:
```python
CHUNK_SIZE = 1500      # Chunks m√°s grandes
CHUNK_OVERLAP = 200    # M√°s superposici√≥n entre chunks
```
